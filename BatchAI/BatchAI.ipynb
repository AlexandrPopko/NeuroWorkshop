{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatchAI Training: MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sample, we will create a cluster for BatchAI training. You need to setup the following:\n",
    " * Create Service Principal as described [here](https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-authenticate-service-principal-cli)\n",
    " * Azure Storage Account to store initial data\n",
    " * Create file share in that storage account and place `ConvNet_MNIST.py` and both data files there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "from azure.storage.file import FileService\n",
    "from azure.storage.blob import BlockBlobService\n",
    "import azure.mgmt.batchai.models as models\n",
    "import azure.mgmt.batchai as batchai\n",
    "from azure.common.credentials import ServicePrincipalCredentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's specify different parameters here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tenant = \"--place correct value here--\"\n",
    "subscription = \"--place correct value here--\"\n",
    "resource_group_name = \"batchai\"\n",
    "\n",
    "storage_account_name = \"batchaidemo\"\n",
    "storage_account_key = \"--place correct value here--\"\n",
    "fileshare = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create `credentials` object to access everything using our Service principal credentials, and then `client` object to manage BatchAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "credentials = ServicePrincipalCredentials(client_id=\"--place correct value here--\",\n",
    "                                          secret=\"--place correct value here--\",\n",
    "                                          token_uri=\"https://login.microsoftonline.com/{0}/oauth2/token\".format(tenant))\n",
    "client = batchai.BatchAIManagementClient(\n",
    "    credentials=credentials,\n",
    "    subscription_id=subscription,\n",
    "    base_url=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get reference to resource group where all objects will be placed. If the group does not exist - it is created automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from azure.mgmt.resource import ResourceManagementClient\n",
    "\n",
    "resource_management_client = ResourceManagementClient(credentials=credentials, subscription_id=subscription)\n",
    "\n",
    "group = resource_management_client.resource_groups.create_or_update(\n",
    "        resource_group_name, {'location': 'northeurope'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create cluster\n",
    "\n",
    "Cluster is a resource pool that will accept jobs. Here we define the configuration of the cluster and create it. Once created, it takes resources, so you should destroy it once done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.mgmt.batchai.models.cluster.Cluster at 0x6519198>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_name = 'shwarscluster'\n",
    "relative_mount_point = 'azurefileshare'\n",
    "\n",
    "parameters = models.ClusterCreateParameters(\n",
    "    location='northeurope',\n",
    "    vm_size='STANDARD_NC6',\n",
    "    user_account_settings=models.UserAccountSettings(\n",
    "         admin_user_name=\"shwars\",\n",
    "         admin_user_password=\"ShwarZ13!\"),\n",
    "    scale_settings=models.ScaleSettings(\n",
    "         manual=models.ManualScaleSettings(target_node_count=1)\n",
    "     ),\n",
    "    node_setup=models.NodeSetup(\n",
    "        # Mount shared volumes to the host\n",
    "         mount_volumes=models.MountVolumes(\n",
    "             azure_file_shares=[\n",
    "                 models.AzureFileShareReference(\n",
    "                     account_name=storage_account_name,\n",
    "                     credentials=models.AzureStorageCredentialsInfo(\n",
    "         account_key=storage_account_key),\n",
    "         azure_file_url='https://{0}.file.core.windows.net/{1}'.format(\n",
    "               storage_account_name, fileshare),\n",
    "                  relative_mount_path = relative_mount_point)],\n",
    "         ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "client.clusters.create(resource_group_name, cluster_name, parameters).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now look in the Azure Portal to see the cluster. You can also do the step above through the azure portal. Now we need to check the cluster status before submitting jobs to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster state: steady Target: 1; Allocated: 1; Idle: 0; Unusable: 0; Running: 0; Preparing: 1; leaving: 0\n"
     ]
    }
   ],
   "source": [
    "cluster = client.clusters.get(resource_group_name, cluster_name)\n",
    "print('Cluster state: {0} Target: {1}; Allocated: {2}; Idle: {3}; '\n",
    "      'Unusable: {4}; Running: {5}; Preparing: {6}; leaving: {7}'.format(\n",
    "    cluster.allocation_state,\n",
    "    cluster.scale_settings.manual.target_node_count,\n",
    "    cluster.current_node_count,\n",
    "    cluster.node_state_counts.idle_node_count,\n",
    "    cluster.node_state_counts.unusable_node_count,\n",
    "    cluster.node_state_counts.running_node_count,\n",
    "    cluster.node_state_counts.preparing_node_count,\n",
    "    cluster.node_state_counts.leaving_node_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and submit job\n",
    "\n",
    "A job is basically a task to perform. In our case, we create a job based on docker image, so when job is submitted, the following happens:\n",
    " * Job is scheduled on the cluster\n",
    " * Chosen VM gets the docker image\n",
    " * The image is started with the provided command line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_name = 'trainjob'\n",
    "\n",
    "parameters = models.job_create_parameters.JobCreateParameters(\n",
    "     location='northeurope',\n",
    "     cluster=models.ResourceId(id=cluster.id),\n",
    "     # The number of VMs in the cluster to use\n",
    "     node_count=1,\n",
    "\n",
    "     # Override the path where the std out and std err files will be written to.\n",
    "     # In this case we will write these out to an Azure Files share\n",
    "     std_out_err_path_prefix='$AZ_BATCHAI_MOUNT_ROOT/{0}'.format(relative_mount_point),\n",
    "\n",
    "     input_directories=[models.InputDirectory(\n",
    "         id='SAMPLE',\n",
    "         path='$AZ_BATCHAI_MOUNT_ROOT/{0}/data'.format(relative_mount_point))],\n",
    "\n",
    "     # Specify directories where files will get written to\n",
    "     output_directories=[models.OutputDirectory(\n",
    "        id='MODEL',\n",
    "        path_prefix='$AZ_BATCHAI_MOUNT_ROOT/{0}'.format(relative_mount_point),\n",
    "        path_suffix=\"Models\")],\n",
    "\n",
    "     # Container configuration\n",
    "     container_settings=models.ContainerSettings(\n",
    "         image_source_registry=models.ImageSourceRegistry(image='microsoft/cntk:2.1-gpu-python3.5-cuda8.0-cudnn6.0')),\n",
    "\n",
    "     # Toolkit specific settings\n",
    "     cntk_settings = models.CNTKsettings(\n",
    "        python_script_file_path='$AZ_BATCHAI_INPUT_SAMPLE/ConvNet_MNIST.py',\n",
    "        command_line_args='$AZ_BATCHAI_INPUT_SAMPLE $AZ_BATCHAI_OUTPUT_MODEL')\n",
    " )\n",
    "\n",
    "# Create the job\n",
    "client.jobs.create(resource_group_name, job_name, parameters).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can monitor job status to check when it is done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job = client.jobs.get(resource_group_name, job_name)\n",
    "print('Job state: {0} '.format(job.execution_state.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we can get job results. They are also available on the file share that we provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = client.jobs.list_output_files(resource_group_name, job_name, models.JobsListOutputFilesOptions(outputdirectoryid=\"stdouterr\"))\n",
    "\n",
    "for file in list(files):\n",
    "     print('file: {0}, download url: {1}'.format(file.name, file.download_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "To make sure that resources do not eat our azure subscription, we need to delete the job and the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client.jobs.delete(resource_group_name, job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client.clusters.delete(resource_group_name, cluster_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
