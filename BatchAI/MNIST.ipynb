{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image recognition: MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's do some imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import cntk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To feed data to the network, we create a data reader - `MinibatchSource`. In our case input data are text files, so we use `CTFDeserializer` to parse them. In case of real images, we use `ImageDeserializer`.\n",
    "\n",
    "Data Readers can take care of:\n",
    " * Applying filters to the data on the fly (image resize, crop, etc.)\n",
    " * Data Augmentation\n",
    " * Cycling over the data as many times as needed\n",
    " * Data shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_reader(path, is_training, input_dim, label_dim):\n",
    "    return cntk.io.MinibatchSource(cntk.io.CTFDeserializer(path, cntk.io.StreamDefs(\n",
    "        features  = cntk.io.StreamDef(field='features', shape=input_dim),\n",
    "        labels    = cntk.io.StreamDef(field='labels',   shape=label_dim)\n",
    "    )), randomize=is_training, max_sweeps = cntk.io.INFINITELY_REPEAT if is_training else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define some network parameters and CNN network architecture. In this code, `z` represents the computation graph for our neural network, and `input_var` and `label_var` are the data which we feed to the network during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_height = 28\n",
    "image_width  = 28\n",
    "num_channels = 1\n",
    "input_dim = image_height * image_width * num_channels\n",
    "num_output_classes = 10\n",
    "\n",
    "# Input variables denoting the features and label data\n",
    "input_var = cntk.ops.input((num_channels, image_height, image_width), np.float32)\n",
    "label_var = cntk.ops.input(num_output_classes, np.float32)\n",
    "\n",
    "# Instantiate the feedforward classification model\n",
    "scaled_input = cntk.ops.element_times(cntk.ops.constant(0.00390625), input_var)\n",
    "\n",
    "with cntk.layers.default_options(activation=cntk.ops.relu, pad=False): \n",
    "    conv1 = cntk.layers.Convolution2D((5,5), 32, pad=True)(scaled_input)\n",
    "    pool1 = cntk.layers.MaxPooling((3,3), (2,2))(conv1)\n",
    "    conv2 = cntk.layers.Convolution2D((3,3), 48)(pool1)\n",
    "    pool2 = cntk.layers.MaxPooling((3,3), (2,2))(conv2)\n",
    "    conv3 = cntk.layers.Convolution2D((3,3), 64)(pool2)\n",
    "    f4    = cntk.layers.Dense(96)(conv3)\n",
    "    drop4 = cntk.layers.Dropout(0.5)(f4)\n",
    "    z     = cntk.layers.Dense(num_output_classes, activation=None)(drop4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define loss function to minimize, and some training parameters and objects. `trainer` is the main object that is used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ce = cntk.losses.cross_entropy_with_softmax(z, label_var)\n",
    "pe = cntk.metrics.classification_error(z, label_var)\n",
    "\n",
    "reader_train = create_reader('Train-28x28_cntk_text.txt', True, input_dim, num_output_classes)\n",
    "\n",
    "# Training config\n",
    "epoch_size = 60000                    \n",
    "minibatch_size = 64\n",
    "max_epochs = 10\n",
    "\n",
    "# Set learning parameters\n",
    "lr_per_sample    = [0.001]*10 + [0.0005]*10 + [0.0001]\n",
    "lr_schedule      = cntk.learning_rate_schedule(lr_per_sample, cntk.learners.UnitType.sample, epoch_size)\n",
    "mm_time_constant = [0]*5 + [1024]\n",
    "mm_schedule      = cntk.learners.momentum_as_time_constant_schedule(mm_time_constant, epoch_size)\n",
    "\n",
    "# Instantiate the trainer object to drive the model training\n",
    "learner = cntk.learners.momentum_sgd(z.parameters, lr_schedule, mm_schedule)\n",
    "progress_printer = cntk.logging.ProgressPrinter(tag='Training',\n",
    "                                                num_epochs=max_epochs)\n",
    "trainer = cntk.Trainer(z, (ce, pe), learner, progress_printer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here actual training happens. `input_map` specifies correspondence between data in input reader and variables. Then we loop through all samples and call `trainer.train_minibatch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 98778 parameters in 10 parameter tensors.\n",
      "\n",
      "Learning rate per 1 samples: 0.001\n",
      "Momentum per 1 samples: 0.0\n",
      "Finished Epoch[1 of 10]: [Training] loss = 0.404131 * 60000, metric = 12.96% * 60000 21.392s (2804.8 samples/s);\n",
      "Finished Epoch[2 of 10]: [Training] loss = 0.104888 * 60000, metric = 3.00% * 60000 3.573s (16792.6 samples/s);\n",
      "Finished Epoch[3 of 10]: [Training] loss = 0.077668 * 60000, metric = 2.24% * 60000 3.605s (16643.6 samples/s);\n",
      "Finished Epoch[4 of 10]: [Training] loss = 0.063216 * 60000, metric = 1.84% * 60000 3.575s (16783.2 samples/s);\n",
      "Finished Epoch[5 of 10]: [Training] loss = 0.054544 * 60000, metric = 1.60% * 60000 3.582s (16750.4 samples/s);\n",
      "Momentum per 1 samples: 0.999023914182\n",
      "Finished Epoch[6 of 10]: [Training] loss = 0.046677 * 60000, metric = 1.36% * 60000 3.590s (16713.1 samples/s);\n",
      "Finished Epoch[7 of 10]: [Training] loss = 0.040269 * 60000, metric = 1.21% * 60000 3.553s (16887.1 samples/s);\n",
      "Finished Epoch[8 of 10]: [Training] loss = 0.037695 * 60000, metric = 1.12% * 60000 3.555s (16877.6 samples/s);\n",
      "Finished Epoch[9 of 10]: [Training] loss = 0.034654 * 60000, metric = 1.02% * 60000 3.568s (16816.1 samples/s);\n",
      "Finished Epoch[10 of 10]: [Training] loss = 0.031231 * 60000, metric = 0.94% * 60000 3.578s (16769.1 samples/s);\n"
     ]
    }
   ],
   "source": [
    "# Define mapping from reader streams to network inputs\n",
    "input_map = {\n",
    "    input_var : reader_train.streams.features,\n",
    "    label_var : reader_train.streams.labels\n",
    "}\n",
    "\n",
    "cntk.logging.log_number_of_parameters(z) ; print()\n",
    "\n",
    "# Get minibatches of images to train with and perform model training\n",
    "for epoch in range(max_epochs):       # loop over epochs\n",
    "    sample_count = 0\n",
    "    while sample_count < epoch_size:  # loop over minibatches in the epoch\n",
    "        data = reader_train.next_minibatch(min(minibatch_size, epoch_size - sample_count), input_map=input_map) # fetch minibatch.\n",
    "        trainer.train_minibatch(data)                                   # update model with it\n",
    "        sample_count += data[label_var].num_samples                     # count samples processed so far\n",
    "\n",
    "    trainer.summarize_training_progress()\n",
    "    # z.save(os.path.join(model_path, \"ConvNet_MNIST_{}.dnn\".format(epoch)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test it on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results: Minibatch[1-11]: errs = 0.83% * 10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "reader_test = create_reader('Test-28x28_cntk_text.txt', False, input_dim, num_output_classes)\n",
    "\n",
    "input_map = {\n",
    "    input_var : reader_test.streams.features,\n",
    "    label_var : reader_test.streams.labels\n",
    "}\n",
    "\n",
    "# Test data for trained model\n",
    "epoch_size = 10000\n",
    "minibatch_size = 1024\n",
    "\n",
    "# Process minibatches and evaluate the model\n",
    "metric_numer    = 0\n",
    "metric_denom    = 0\n",
    "sample_count    = 0\n",
    "minibatch_index = 0\n",
    "\n",
    "while sample_count < epoch_size:\n",
    "    current_minibatch = min(minibatch_size, epoch_size - sample_count)\n",
    "\n",
    "    # Fetch next test min batch.\n",
    "    data = reader_test.next_minibatch(current_minibatch, input_map=input_map)\n",
    "\n",
    "    # Minibatch data to be trained with\n",
    "    metric_numer += trainer.test_minibatch(data) * current_minibatch\n",
    "    metric_denom += current_minibatch\n",
    "\n",
    "    # Keep track of the number of samples processed so far.\n",
    "    sample_count += data[label_var].num_samples\n",
    "    minibatch_index += 1\n",
    "\n",
    "print(\"\")\n",
    "print(\"Final Results: Minibatch[1-{}]: errs = {:0.2f}% * {}\".format(minibatch_index+1, (metric_numer*100.0)/metric_denom, metric_denom))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
